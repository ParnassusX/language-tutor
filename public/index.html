<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Language Tutor - Live Agent</title>
    <link rel="icon" type="image/x-icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ðŸŽ“</text></svg>">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f7fa;
            color: #333;
        }
        
        .container {
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            padding: 20px;
            margin-top: 20px;
        }
        
        h1 {
            color: #2c3e50;
            text-align: center;
            margin-bottom: 30px;
        }
        
        .status {
            padding: 10px;
            border-radius: 5px;
            margin-bottom: 20px;
            text-align: center;
            font-weight: bold;
        }
        
        .connected {
            background-color: #d4edda;
            color: #155724;
        }
        
        .disconnected {
            background-color: #f8d7da;
            color: #721c24;
        }
        
        .tts-controls {
            margin: 15px 0;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 5px;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .tts-controls label {
            font-weight: bold;
            margin-right: 10px;
        }
        
        .tts-controls select, .tts-controls button {
            padding: 5px 10px;
            border-radius: 4px;
            border: 1px solid #ced4da;
        }
        
        .tts-controls button {
            background-color: #007bff;
            color: white;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 5px;
        }
        
        .tts-controls button:disabled {
            background-color: #6c757d;
            cursor: not-allowed;
        }
        
        .speaking {
            color: #28a745;
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        
        .controls {
            display: flex;
            flex-direction: column;
            gap: 15px;
            margin-bottom: 20px;
        }
        
        button {
            background-color: #3498db;
            color: white;
            border: none;
            padding: 12px 20px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            transition: background-color 0.3s;
        }
        
        button:hover {
            background-color: #2980b9;
        }
        
        button:disabled {
            background-color: #95a5a6;
            cursor: not-allowed;
        }
        
        #recordButton.recording {
            background-color: #e74c3c;
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        
        .conversation {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            margin-bottom: 20px;
            background-color: #f9f9f9;
        }
        
        .message {
            margin-bottom: 15px;
            padding: 10px 15px;
            border-radius: 15px;
            max-width: 80%;
            word-wrap: break-word;
        }
        
        .user-message {
            background-color: #e3f2fd;
            margin-left: auto;
            border-bottom-right-radius: 5px;
        }
        
        .assistant-message {
            background-color: #e8f5e9;
            margin-right: auto;
            border-bottom-left-radius: 5px;
        }
        
        .timestamp {
            font-size: 0.8em;
            color: #7f8c8d;
            margin-top: 5px;
        }
        
        .settings {
            margin-top: 20px;
            padding: 15px;
            background-color: #f1f8ff;
            border-radius: 5px;
        }
        
        select, input {
            padding: 8px;
            border-radius: 4px;
            border: 1px solid #ddd;
            margin-right: 10px;
        }
        
        .call-button {
            font-size: 1.2em;
            padding: 12px 30px;
            transition: all 0.3s ease;
        }
        
        .call-button.active-call {
            background-color: #dc3545;
            transform: scale(1.05);
            box-shadow: 0 0 15px rgba(220, 53, 69, 0.5);
        }
        
        .call-timer {
            text-align: center;
            font-size: 1.2em;
            margin: 10px 0;
            font-family: monospace;
            display: none;
            color: #28a745;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Language Tutor - Live Agent</h1>
        
        <div id="status" class="status disconnected">Disconnected from server</div>
        
        <div class="tts-controls">
            <label for="voiceSelect" class="sr-only">Choose a voice for text-to-speech</label>
            <select id="voiceSelect" class="form-control" aria-label="Select a voice for text-to-speech">
                <option value="">Select a voice</option>
            </select>
            <button id="callButton" class="btn call-button" disabled>
                <i class="fas fa-phone"></i> Start Call
            </button>
            <div id="callTimer" class="call-timer">00:00</div>
        </div>
        
        <div class="controls">
            <button id="connectButton">Connect</button>
            <button id="testTTS" class="btn" title="Test TTS">
                <i class="fas fa-volume-up"></i> Test Voice
            </button>
            <button id="sendTextButton" disabled>Send Test Message</button>
        </div>
        
        <div class="conversation" id="conversation">
            <!-- Messages will appear here -->
        </div>
        
        <div class="settings">
            <h3>Settings</h3>
            <div>
                <label for="languageSelect">Language: </label>
                <select id="languageSelect">
                    <option value="de">German (Deutsch)</option>
                    <option value="en">English</option>
                    <option value="fr">French (FranÃ§ais)</option>
                    <option value="es">Spanish (EspaÃ±ol)</option>
                </select>
                
                <label for="serverUrl">Server: </label>
                <input type="text" id="serverUrl" value="ws://localhost:3001" style="width: 200px;">
            </div>
        </div>
    </div>

    <script>
        // DOM Elements - will be initialized in initDOMReferences()
        let connectButton, callButton, sendTextButton, statusDiv, conversationDiv, serverUrlInput, voiceSelect, callTimer;
        
        // Audio state management
        const audioState = {
            // Audio context and playback
            audioContext: null,
            audioSource: null,
            audioQueue: [],
            isPlaying: false,
            isRecording: false,
            
            // Audio recording
            mediaRecorder: null,
            audioChunks: [],
            
            // Speech synthesis
            synth: window.speechSynthesis || null,
            voices: [],
            selectedVoice: 'aura-asteria-en',
            isSpeaking: false,
            
            // WebSocket and connection
            socket: null,
            clientId: null,
            
            // Audio buffer for TTS
            audioBuffer: null,
            
            // Initialization flag
            initialized: false
        };
        
        // Initialize audio system when the page loads
        document.addEventListener('DOMContentLoaded', initAudioSystem);
        
        // Call timer variables
        let callStartTime = 0;
        let callTimerInterval = null;
        
        // Initialize DOM references
        function initDOMReferences() {
            // Get all required DOM elements
            connectButton = document.getElementById('connectButton');
            callButton = document.getElementById('callButton');
            sendTextButton = document.getElementById('sendTextButton');
            statusDiv = document.getElementById('status');
            conversationDiv = document.getElementById('conversation');
            serverUrlInput = document.getElementById('serverUrl');
            voiceSelect = document.getElementById('voiceSelect');
            callTimer = document.getElementById('callTimer');
            
            // Check if all required elements were found
            const elements = {
                connectButton,
                callButton,
                statusDiv,
                conversationDiv,
                serverUrlInput,
                voiceSelect,
                callTimer
            };
            
            const allElementsFound = Object.values(elements).every(el => {
                if (!el) {
                    console.error('Missing required DOM element');
                    return false;
                }
                return true;
            });
            
            if (!allElementsFound) {
                console.error('Failed to initialize all DOM elements');
                return false;
            }
            
            return true;
        }
        
        // Update UI based on connection status
        function updateStatus(status) {
            if (!statusDiv) return;
            
            // If status is an object, extract the message
            const statusMessage = typeof status === 'object' ? 
                (status.message || 'Connected') : 
                (status === 'connected' ? 'Connected to server' : 'Disconnected');
                
            statusDiv.textContent = statusMessage;
            const isConnected = status === 'connected' || (typeof status === 'object' && status.status === 'connected');
            statusDiv.className = `status ${isConnected ? 'connected' : 'disconnected'}`;
            
            if (connectButton) {
                connectButton.textContent = isConnected ? 'Disconnect' : 'Connect';
            }
            
            if (callButton) {
                callButton.disabled = !isConnected;
            }
            
            return isConnected;
        }
        
        // Update UI
        function updateUI() {
            const isConnected = socket && socket.readyState === WebSocket.OPEN;
            
            connectButton.textContent = isConnected ? 'Disconnect' : 'Connect';
            callButton.disabled = !isConnected;
            sendTextButton.disabled = !isConnected;
            
            if (isConnected) {
                statusDiv.textContent = clientId ? `Connected as ${clientId}` : 'Connected to server';
                statusDiv.className = 'status connected';
            } else {
                statusDiv.textContent = 'Disconnected from server';
                statusDiv.className = 'status disconnected';
            }
            
            if (isRecording) {
                callButton.innerHTML = '<i class="fas fa-phone-slash"></i> End Call';
                callButton.classList.add('active-call');
            } else {
                callButton.innerHTML = '<i class="fas fa-phone"></i> Start Call';
                callButton.classList.remove('active-call');
            }
        }
        
        // Update call timer
        function updateCallTimer() {
            if (!callStartTime) return;
            const elapsed = Math.floor((Date.now() - callStartTime) / 1000);
            const minutes = Math.floor(elapsed / 60).toString().padStart(2, '0');
            const seconds = (elapsed % 60).toString().padStart(2, '0');
            if (callTimer) {
                callTimer.textContent = `${minutes}:${seconds}`;
            }
        }
        
        // Start call timer
        function startCallTimer() {
            if (callTimerInterval) {
                clearInterval(callTimerInterval);
            }
            callStartTime = Date.now();
            updateCallTimer(); // Update immediately
            callTimerInterval = setInterval(updateCallTimer, 1000);
            if (callTimer) {
                callTimer.style.display = 'block';
            }
            console.log('Call timer started');
        }
        
        // Stop call timer
        function stopCallTimer() {
            if (callTimerInterval) {
                clearInterval(callTimerInterval);
                callTimerInterval = null;
            }
            callStartTime = 0;
            if (callTimer) {
                callTimer.style.display = 'none';
                callTimer.textContent = '00:00';
            }
            console.log('Call timer stopped');
        }
        
        // Initialize audio context
        async function initAudioContext() {
            if (window.audioContextInitialized) {
                console.log('Audio context already initialized');
                return window.audioContext;
            }
            
            try {
                // Create audio context with desired sample rate (16kHz for Deepgram)
                window.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000,
                    latencyHint: 'interactive'
                });
                
                // Create audio worklet for processing
                try {
                    await window.audioContext.audioWorklet.addModule('audio-processor.js');
                    window.audioWorkletNode = new AudioWorkletNode(window.audioContext, 'audio-processor');
                    
                    // Connect nodes: source -> worklet -> destination
                    window.audioSourceNode = window.audioContext.createMediaStreamSource(new MediaStream());
                    window.audioDestinationNode = window.audioContext.destination;
                    
                    window.audioSourceNode.connect(window.audioWorkletNode);
                    window.audioWorkletNode.connect(window.audioDestinationNode);
                    
                    // Handle audio data from worklet
                    window.audioWorkletNode.port.onmessage = (event) => {
                        if (socket && socket.readyState === WebSocket.OPEN) {
                            socket.send(event.data);
                        }
                    };
                    
                    window.audioContextInitialized = true;
                    console.log('Audio context and worklet initialized');
                    return window.audioContext;
                    
                } catch (error) {
                    console.error('Error initializing audio worklet:', error);
                    // Fallback to ScriptProcessor if worklet fails
                    return initScriptProcessor();
                }
                
            } catch (error) {
                console.error('Error initializing audio context:', error);
                throw error;
            }
        }
        
        // Fallback to ScriptProcessor
        function initScriptProcessor() {
            console.warn('Using deprecated ScriptProcessorNode as fallback');
            const bufferSize = 4096;
            const processor = window.audioContext.createScriptProcessor(bufferSize, 1, 1);
            
            processor.onaudioprocess = (e) => {
                if (!isRecording) return;
                
                const inputData = e.inputBuffer.getChannelData(0);
                const pcmData = new Int16Array(inputData.length);
                
                // Convert float32 to int16
                for (let i = 0; i < inputData.length; i++) {
                    pcmData[i] = Math.max(-1, Math.min(1, inputData[i])) * 0x7FFF;
                }
                
                if (socket && socket.readyState === WebSocket.OPEN) {
                    socket.send(pcmData.buffer);
                }
            };
            
            window.audioSourceNode.connect(processor);
            processor.connect(window.audioContext.destination);
            
            return window.audioContext;
        }
        
        /**
         * Connect to the WebSocket server
         */
        function connect() {
            // Get the server URL from the input field or use default
            const serverUrl = document.getElementById('serverUrl')?.value || 'ws://localhost:3001';
            
            // Close existing connection if any
            if (audioState.socket) {
                audioState.socket.close();
            }
            
            // Create new WebSocket connection
            const socket = new WebSocket(serverUrl);
            audioState.socket = socket;
            
            // Connection opened
            socket.addEventListener('open', (event) => {
                console.log('Connected to WebSocket server');
                updateStatus('connected');
                addMessage('system', 'Connected to server');
                
                // Request available voices from server
                socket.send(JSON.stringify({
                    type: 'get_voices'
                }));
            });
            
            // Listen for messages
            socket.addEventListener('message', (event) => {
                try {
                    const data = JSON.parse(event.data);
                    console.log('Message from server:', data);
                    
                    // Handle different message types
                    switch (data.type) {
                        case 'initialization':
                            audioState.clientId = data.clientId;
                            console.log('Client ID:', data.clientId);
                            break;
                            
                        case 'voices':
                            updateVoiceList(data.voices);
                            break;
                            
                        case 'tts_audio':
                            handleTTSAudio(data.audio, data.format);
                            break;
                            
                        case 'transcript':
                            addMessage('assistant', data.text);
                            break;
                            
                        case 'error':
                            console.error('Server error:', data.message);
                            addMessage('error', data.message);
                            break;
                            
                        default:
                            console.log('Unknown message type:', data.type);
                    }
                } catch (error) {
                    console.error('Error processing message:', error, event.data);
                }
            });
            
            // Connection closed
            socket.addEventListener('close', (event) => {
                console.log('Disconnected from WebSocket server');
                updateStatus('disconnected');
                addMessage('system', 'Disconnected from server');
                
                // Attempt to reconnect after a delay
                setTimeout(() => {
                    console.log('Attempting to reconnect...');
                    connect();
                }, 3000);
            });
            
            // Handle errors
            socket.addEventListener('error', (error) => {
                console.error('WebSocket error:', error);
                updateStatus('error');
                addMessage('error', 'Connection error');
            });
        }
        
        /**
         * Toggle connection to the WebSocket server
         */
        function toggleConnection() {
            if (audioState.socket && audioState.socket.readyState === WebSocket.OPEN) {
                audioState.socket.close();
            } else {
                connect();
            }
        }
        
        /**
         * Update the voice list in the UI
         * @param {Array} voices - List of available voices
         */
        function updateVoiceList(voices) {
            if (!voiceSelect) return;
            
            // Clear existing options
            voiceSelect.innerHTML = '';
            
            // Add default option
            const defaultOption = document.createElement('option');
            defaultOption.value = '';
            defaultOption.textContent = 'Select a voice';
            defaultOption.disabled = true;
            defaultOption.selected = true;
            voiceSelect.appendChild(defaultOption);
            
            // Add available voices
            if (voices && voices.length > 0) {
                voices.forEach(voice => {
                    const option = document.createElement('option');
                    option.value = voice.voice_id;
                    option.textContent = `${voice.name} (${voice.language})`;
                    voiceSelect.appendChild(option);
                });
                
                // Select the first voice by default
                if (voices.length > 0) {
                    voiceSelect.value = voices[0].voice_id;
                    audioState.selectedVoice = voices[0].voice_id;
                }
            } else {
                const noVoices = document.createElement('option');
                noVoices.textContent = 'No voices available';
                noVoices.disabled = true;
                voiceSelect.appendChild(noVoices);
            }
        }
        
        /**
         * Handle TTS audio data from the server
         * @param {string} audioData - Base64 encoded audio data
         * @param {string} format - Audio format (e.g., 'wav', 'mp3')
         */
        async function handleTTSAudio(audioData, format = 'wav') {
            try {
                console.log('Received TTS audio data, format:', format);
                
                // Convert base64 to ArrayBuffer
                const binaryString = atob(audioData);
                const len = binaryString.length;
                const bytes = new Uint8Array(len);
                
                for (let i = 0; i < len; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                // Decode the audio data
                const audioContext = audioState.audioContext || new (window.AudioContext || window.webkitAudioContext)();
                audioState.audioContext = audioContext;
                
                // Resume audio context if suspended
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                // Decode the audio data
                const audioBuffer = await audioContext.decodeAudioData(bytes.buffer);
                
                // Create a buffer source
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                
                // Connect to the destination (speakers)
                source.connect(audioContext.destination);
                
                // Set up the onended handler
                source.onended = () => {
                    console.log('Playback finished');
                    audioState.isPlaying = false;
                    
                    // Process the next audio in the queue if available
                    if (audioState.audioQueue.length > 0) {
                        const nextAudio = audioState.audioQueue.shift();
                        handleTTSAudio(nextAudio.audioData, nextAudio.format);
                    }
                };
                
                // Start playback
                console.log('Starting audio playback');
                audioState.isPlaying = true;
                source.start(0);
                
                // Store the source for potential cleanup
                audioState.audioSource = source;
                
            } catch (error) {
                console.error('Error playing TTS audio:', error);
                audioState.isPlaying = false;
                
                // Try to play the next audio in the queue if available
                if (audioState.audioQueue.length > 0) {
                    const nextAudio = audioState.audioQueue.shift();
                    handleTTSAudio(nextAudio.audioData, nextAudio.format);
                }
            }
        }
        
        // Initialize the app
        document.addEventListener('DOMContentLoaded', async () => {
            if (!initDOMReferences()) {
                console.error('Failed to initialize DOM references');
                return;
            }
            
            try {
                // Initialize audio first
                await initAudioContext();
                
                // Setup UI and event listeners
                setupEventListeners();
                setupTTS();
                
                // Connect to server
                connect();
                
            } catch (error) {
                console.error('Initialization error:', error);
                addMessage('error', `Initialization failed: ${error.message}`);
            }
        });
        
        // Set up all event listeners in one place
        function setupEventListeners() {
            if (connectButton) {
                connectButton.addEventListener('click', toggleConnection);
            }
            
            if (callButton) {
                callButton.addEventListener('click', toggleCall);
            }
            
            if (sendTextButton) {
                sendTextButton.addEventListener('click', sendTestMessage);
            }
            
            // Handle Enter key in message input
            const messageInput = document.getElementById('messageInput');
            if (messageInput) {
                messageInput.addEventListener('keypress', (e) => {
                    if (e.key === 'Enter') {
                        sendTestMessage();
                    }
                });
            }
        }
        
        // Set up text-to-speech
        function setupTTS() {
            // Initialize AudioContext on user interaction
            const initAudioContext = () => {
                if (!audioContext) {
                    try {
                        audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        console.log('Audio context initialized, sample rate:', audioContext.sampleRate);
                        
                        // Log audio context state changes
                        audioContext.onstatechange = () => {
                            console.log('AudioContext state changed to:', audioContext.state);
                        };
                        
                        // Resume audio context if it's in a suspended state
                        if (audioContext.state === 'suspended') {
                            console.log('AudioContext is suspended, attempting to resume...');
                            audioContext.resume().then(() => {
                                console.log('AudioContext resumed successfully');
                            }).catch(error => {
                                console.error('Failed to resume AudioContext:', error);
                            });
                        }
                    } catch (error) {
                        console.error('Failed to initialize AudioContext:', error);
                    }
                } else {
                    console.log('AudioContext already initialized');
                }
            };
            
            // Set up test voice button if it exists
            const ttsButton = document.getElementById('testTTS');
            if (ttsButton) {
                ttsButton.addEventListener('click', () => {
                    initAudioContext();
                    const testText = 'This is a test of the Deepgram text-to-speech system.';
                    requestTTS(testText, selectedVoice);
                });
            } else {
                console.warn('Test TTS button not found');
            }
            
            // Initialize voice selection if it exists
            if (voiceSelect) {
                voiceSelect.innerHTML = '<option value="" disabled>Loading voices...</option>';
                
                // Add voice selection change handler
                voiceSelect.addEventListener('change', (e) => {
                    selectedVoice = e.target.value;
                    console.log('Selected voice:', selectedVoice);
                });
            } else {
                console.warn('Voice select element not found');
            }
            
            // Initialize audio context on first user interaction
            document.addEventListener('click', initAudioContext, { once: true });
        }
        
        // Function to request TTS from server
        function requestTTS(text, voiceId) {
            if (!text) {
                console.error('No text provided for TTS');
                return;
            }
            
            if (!socket || socket.readyState !== WebSocket.OPEN) {
                console.error('WebSocket not connected');
                return;
            }
            
            console.log('Requesting TTS for text:', text, 'with voice:', voiceId);
            
            // Show speaking indicator
            isSpeaking = true;
            updateUI();
            
            try {
                // Send TTS request to server
                socket.send(JSON.stringify({
                    type: 'tts_request',
                    text: text,
                    voiceId: voiceId || 'aura-asteria-en' // Fallback to default voice
                }));
                
                console.log('TTS request sent');
                
                // Add to chat as assistant message
                addMessage('assistant', text);
            } catch (error) {
                console.error('Error sending TTS request:', error);
                isSpeaking = false;
                updateUI();
            }
        }
        
                        // Set up the onended handler
                        source.onended = () => {
                            console.log('Audio playback finished');
                            audioState.isPlaying = false;
                            
                            // Play next chunk if available
                            if (audioState.audioQueue.length > 0) {
                                playNextChunk();
                            } else {
                                resolve();
                            }
                        };
                        
                        // Start playback
                        try {
                            console.log('Starting audio playback');
                            audioState.isPlaying = true;
                            source.start(0);
                        } catch (error) {
                            console.error('Error starting audio playback:', error);
                            audioState.isPlaying = false;
                            reject(error);
                        }
            });
        }
        
        // Convert raw PCM to WAV format
        function encodeWAV(samples, sampleRate) {
            const buffer = new ArrayBuffer(44 + samples.length * 2);
            const view = new DataView(buffer);
            
            // RIFF identifier
            writeString(view, 0, 'RIFF');
            // File length
            view.setUint32(4, 36 + samples.length * 2, true);
            // RIFF type
            writeString(view, 8, 'WAVE');
            // Format chunk identifier
            writeString(view, 12, 'fmt ');
            // Format chunk length
    view.setUint32(16, 16, true);
    // Sample format (raw)
    view.setUint16(20, 1, true);
    // Channel count (mono)
    view.setUint16(22, 1, true);
    // Sample rate
    view.setUint32(24, sampleRate, true);
    // Byte rate (sampleRate * blockAlign)
    view.setUint32(28, sampleRate * 2, true);
    // Block align (channelCount * bytesPerSample)
    view.setUint16(32, 2, true);
    // Bits per sample
    view.setUint16(34, 16, true);
    // Data chunk identifier
    writeString(view, 36, 'data');
    // Data chunk length
    view.setUint32(40, samples.length * 2, true);
    
    // Write the PCM samples
    const floatTo16BitPCM = (output, offset, input) => {
        for (let i = 0; i < input.length; i++, offset += 2) {
            const s = Math.max(-1, Math.min(1, input[i]));
            output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
        }
    };
    
    // Write the samples to the view
    const writeOffset = 44;
    for (let i = 0; i < samples.length; i++) {
        view.setInt16(writeOffset + i * 2, samples[i], true);
    }
    
    return new Blob([view], { type: 'audio/wav' });
}

// Helper function to write strings to the DataView
function writeString(view, offset, string) {
    for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
    }

        // Initialize audio system
        async function initAudioSystem() {
            try {
                // Initialize audio context if not already done
                if (!audioState.audioContext) {
                    audioState.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    await audioState.audioContext.resume();
                    console.log('Audio context initialized');
                }
                
                // Load available voices
                await loadVoices();
                
                // Initialize WebSocket connection
                await initWebSocket();
                
                audioState.initialized = true;
                console.log('Audio system initialized');
                return true;
            } catch (error) {
                console.error('Error initializing audio system:', error);
                updateStatus('Error initializing audio system');
                return false;
            }
        }

        // Initialize audio context (kept for backward compatibility)
        async function initAudioContext() {
            if (!audioState.audioContext) {
                try {
                    audioState.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    await audioState.audioContext.resume();
                    console.log('Audio context initialized');
                    return true;
                } catch (error) {
                    console.error('Error initializing audio context:', error);
                    return false;
                }
            }
            return true;
        }

        // Play audio chunk from queue
        async function playAudioChunk(audioData) {
            if (!audioData || audioData.byteLength === 0) {
                console.warn('Received empty audio data');
                return;
            }
            
            try {
                // Ensure audio context is ready
                if (!audioState.audioContext) {
                    console.log('Initializing audio context for playback...');
                    audioState.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    await audioState.audioContext.resume();
                }
                
                // Decode the audio data
                const audioBuffer = await audioState.audioContext.decodeAudioData(audioData.buffer);
                
                // Create a buffer source
                audioState.audioSource = audioState.audioContext.createBufferSource();
                audioState.audioSource.buffer = audioBuffer;
                
                // Connect to destination (speakers)
                audioState.audioSource.connect(audioState.audioContext.destination);
                
                // Set up event handlers
                audioState.audioSource.onended = () => {
                    console.log('Audio playback finished');
                    audioState.isPlaying = false;
                    updateUI();
                };
                
                // Start playback
                console.log('Starting audio playback');
                audioState.isPlaying = true;
                audioState.audioSource.start(0);
                console.log('Started audio playback');
                
            } catch (error) {
                console.error('Error playing audio chunk:', error);
                audioState.isPlaying = false;
                updateStatus('Error playing audio');
            }
        }

        // Play the next audio chunk in the queue if available
        function playNextChunk() {
            if (audioState.audioQueue.length > 0 && !audioState.isPlaying) {
                const chunk = audioState.audioQueue.shift();
                playAudioChunk(chunk);
            } else if (audioState.audioQueue.length === 0) {
                // All chunks played
                audioState.isPlaying = false;
                updateUI();
            }
        }

        // Function to play the next audio chunk in the queue
        function playNextChunk() {
            if (audioQueue.length > 0 && !isPlaying) {
                const chunk = audioQueue.shift();
                playAudioChunk(chunk);
            } else if (audioQueue.length === 0) {
                // All chunks played
                isPlaying = false;
                updateUI();
            }
        }
        
        // Initialize UI
        updateUI();
        
        // Update UI function
        function updateUI() {
            const isConnected = socket && socket.readyState === WebSocket.OPEN;
            
            updateConnectButton(isConnected);
            updateCallButton(isConnected);
            updateSendButton(isConnected);
            updateStatusDisplay(isConnected);
        }
        
        function updateConnectButton(isConnected) {
            if (!connectButton) return;
            connectButton.textContent = isConnected ? 'Disconnect' : 'Connect';
        }
        
        function updateCallButton(isConnected) {
            if (!callButton) return;
            
            callButton.disabled = !isConnected;
            
            if (isRecording) {
                callButton.innerHTML = '<i class="fas fa-phone-slash"></i> End Call';
                callButton.classList.add('active-call');
            } else {
                callButton.innerHTML = '<i class="fas fa-phone"></i> Start Call';
                callButton.classList.remove('active-call');
            }
        }
        
        function updateSendButton(isConnected) {
            if (sendTextButton) {
                sendTextButton.disabled = !isConnected;
            }
        }
        
        function updateStatusDisplay(isConnected) {
            if (!statusDiv) return;
            
            if (isConnected) {
                statusDiv.textContent = clientId ? `Connected as ${clientId}` : 'Connected to server';
                statusDiv.className = 'status connected';
            } else {
                statusDiv.textContent = 'Disconnected from server';
                statusDiv.className = 'status disconnected';
            }
        }
        
        // Toggle call
        function toggleCall() {
            if (isRecording) {
                console.log('Stopping call...');
                stopRecording();
                stopCallTimer();
            } else {
                console.log('Starting call...');
                if (!selectedVoice) {
                    alert('Please select a voice first');
                    return;
                }
                startRecording();
                startCallTimer();
            }
        }
        
        // Toggle connection
        function toggleConnection() {
            if (socket && socket.readyState === WebSocket.OPEN) {
                // End call if active
                if (isRecording) {
                    stopRecording();
                    stopCallTimer();
                }
                disconnect();
            } else {
                connect();
            }
        }
        
        function connect() {
            // Close existing connection if any
            if (socket) {
                try {
                    socket.close();
                } catch (e) {
                    console.warn('Error closing existing socket:', e);
                }
                socket = null;
            }
            
            const serverUrl = serverUrlInput.value.trim() || 'ws://localhost:3001';
            if (!serverUrl) {
                addMessage('system', 'Please enter a valid server URL');
                return false;
            }
            
            addMessage('system', `Connecting to ${serverUrl}...`);
            console.log('Attempting WebSocket connection to:', serverUrl);
            
            try {
                socket = new WebSocket(serverUrl);
                
                // Connection opened
                socket.onopen = (event) => {
                    console.log('WebSocket connection established', event);
                    addMessage('system', 'Connected to server, initializing...');
                    updateStatus('connected');
                    updateUI();
                };
                
                // Handle connection close
                socket.onclose = (event) => {
                    console.log('WebSocket connection closed:', event.code, event.reason);
                    const reason = event.reason || 'Connection closed';
                    const wasClean = event.wasClean ? 'cleanly' : 'unexpectedly';
                    
                    addMessage('system', `Disconnected ${wasClean} (${event.code}): ${reason}`);
                    updateStatus('disconnected');
                    updateUI();
                    
                    // Clear the socket reference
                    socket = null;
                    
                    // Auto-reconnect if this wasn't a normal closure
                    if (event.code !== 1000) { // 1000 is normal closure
                        addMessage('system', 'Attempting to reconnect in 3 seconds...');
                        setTimeout(() => {
                            if (!socket || socket.readyState === WebSocket.CLOSED) {
                                connect();
                            }
                        }, 3000);
                    }
                };
                
                // Handle connection errors
                socket.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    const errorMessage = error.message || 'Connection error';
                    addMessage('system', `Connection error: ${errorMessage}`);
                    updateStatus('error');
                    updateUI();
                    
                    // Attempt to reconnect after a delay
                    if (socket) {
                        socket.close();
                        socket = null;
                    }
                    
                    // Auto-reconnect after 3 seconds
                    setTimeout(() => {
                        if (!socket || socket.readyState === WebSocket.CLOSED) {
                            addMessage('system', 'Attempting to reconnect...');
                            connect();
                        }
                    }, 3000);
                };
                
            } catch (error) {
                console.error('Error setting up WebSocket connection:', error);
                addMessage('error', `Connection setup failed: ${error.message}`);
                updateUI();
                
                // Attempt to reconnect after a delay
                setTimeout(() => {
                    if (!socket || socket.readyState === WebSocket.CLOSED) {
                        addMessage('system', 'Attempting to reconnect...');
                        connect();
                    }
                }, 3000);
            }
        }
        
        function disconnect() {
            if (socket) {
                socket.close();
                socket = null;
                clientId = null;
                updateUI();
            }
        }
        
        async function startRecording() {
            if (isRecording) return;
            
            try {
                // Request access to microphone with specific constraints
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000,
                        channelCount: 1
                    } 
                });
                
                // Log audio track settings for debugging
                const audioTrack = stream.getAudioTracks()[0];
                console.log('Audio track settings:', audioTrack.getSettings());
                
                // Configure audio context for processing
                const audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });
                
                // Create audio processing nodes
                const source = audioContext.createMediaStreamSource(stream);
                const processor = audioContext.createScriptProcessor(4096, 1, 1);
                
                // Connect audio processing nodes
                source.connect(processor);
                processor.connect(audioContext.destination);
                
                // Initialize MediaRecorder with specific MIME type
                const options = {
                    mimeType: 'audio/webm;codecs=opus',
                    audioBitsPerSecond: 16000
                };
                
                mediaRecorder = new MediaRecorder(stream, options);
                audioChunks = [];
                
                // Handle audio data
                processor.onaudioprocess = (e) => {
                    if (!isRecording) return;
                    
                    // Get raw audio data (32-bit floating point)
                    const inputData = e.inputBuffer.getChannelData(0);
                    
                    // Convert to 16-bit PCM for Deepgram
                    const pcmData = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        // Scale float32 to int16
                        pcmData[i] = Math.max(-1, Math.min(1, inputData[i])) * 0x7FFF;
                    }
                    
                    // Send raw PCM data directly over WebSocket
                    if (socket && socket.readyState === WebSocket.OPEN) {
                        socket.send(pcmData.buffer);
                    }
                };
                
                // Handle recording stop
                mediaRecorder.onstop = async () => {
                    // Clean up audio processing
                    processor.disconnect();
                    source.disconnect();
                    audioContext.close();
                    
                    // Notify server that recording has stopped
                    if (socket && socket.readyState === WebSocket.OPEN) {
                        socket.send(JSON.stringify({
                            type: 'audio_end',
                            timestamp: Date.now()
                        }));
                        
                        // Add user message placeholder
                        addMessage('user', '...', new Date().toISOString());
                    }
                    
                    // Stop all tracks in the stream
                    if (stream) {
                        stream.getTracks().forEach(track => track.stop());
                    }
                };
                
                // Start recording
                if (mediaRecorder) {
                    mediaRecorder.start(100);
                    audioState.isRecording = true;
                    updateUI();
                }
                
                if (audioState.audioContext) {
                    console.log('Recording started with settings:', {
                        sampleRate: audioState.audioContext.sampleRate,
                        channels: 1,
                        format: '16-bit PCM'
                    });
                }
                
            } catch (error) {
                console.error('Error starting recording:', error);
                addMessage('error', `Could not access microphone: ${error.message}`);
            }
        }
        
        function stopRecording() {
            if (isRecording && mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                isRecording = false;
                updateUI();
            }
        }
        
        function sendTestMessage() {
            if (!socket || socket.readyState !== WebSocket.OPEN) {
                addMessage('error', 'Not connected to server');
                return;
            }
            
            const testMessage = "This is a test message";
            addMessage('user', testMessage, new Date().toISOString());
            
            socket.send(JSON.stringify({
                type: 'text',
                text: testMessage
            }));
        }
        
        function addMessage(role, text, timestamp = new Date().toISOString()) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}-message`;
            
            const textNode = document.createElement('div');
            textNode.textContent = text;
            
            const timeNode = document.createElement('div');
            timeNode.className = 'timestamp';
            timeNode.textContent = new Date(timestamp).toLocaleTimeString();
            
            messageDiv.appendChild(textNode);
            messageDiv.appendChild(timeNode);
            
            conversationDiv.appendChild(messageDiv);
            conversationDiv.scrollTop = conversationDiv.scrollHeight;
            
            // Auto-scroll to bottom
            window.scrollTo(0, document.body.scrollHeight);
        }
        
        // Handle window unload
        window.addEventListener('beforeunload', () => {
            if (socket) {
                socket.close();
            }
        });
    });
</script>
</body>
</html>
